{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_cQX8dWu4Dv"
      },
      "source": [
        "# Pose Landmarks Detection with MediaPipe Tasks\n",
        "\n",
        "This notebook shows you how to use MediaPipe Tasks Python API to detect pose landmarks from images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYKAJ5nDU8-I"
      },
      "source": [
        "## Visualization utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "s3E6NFV-00Qt"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mediapipe'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Bane6\\Desktop\\P4P\\[MediaPipe_Python_Tasks]_Pose_Landmarker.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Bane6/Desktop/P4P/%5BMediaPipe_Python_Tasks%5D_Pose_Landmarker.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmediapipe\u001b[39;00m \u001b[39mimport\u001b[39;00m solutions\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bane6/Desktop/P4P/%5BMediaPipe_Python_Tasks%5D_Pose_Landmarker.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmediapipe\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m \u001b[39mimport\u001b[39;00m landmark_pb2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bane6/Desktop/P4P/%5BMediaPipe_Python_Tasks%5D_Pose_Landmarker.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'"
          ]
        }
      ],
      "source": [
        "from mediapipe import solutions\n",
        "from mediapipe.framework.formats import landmark_pb2\n",
        "import numpy as np\n",
        "\n",
        "pose_landmarks = './mediapipe-models/pose_landmarker_lite.task'\n",
        "\n",
        "def draw_landmarks_on_image(rgb_image, detection_result):\n",
        "  pose_landmarks_list = detection_result.pose_landmarks\n",
        "  annotated_image = np.copy(rgb_image)\n",
        "\n",
        "  # Loop through the detected poses to visualize.\n",
        "  for idx in range(len(pose_landmarks_list)):\n",
        "    pose_landmarks = pose_landmarks_list[idx]\n",
        "\n",
        "    # Draw the pose landmarks.\n",
        "    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
        "    pose_landmarks_proto.landmark.extend([\n",
        "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks\n",
        "    ])\n",
        "    solutions.drawing_utils.draw_landmarks(\n",
        "      annotated_image,\n",
        "      pose_landmarks_proto,\n",
        "      solutions.pose.POSE_CONNECTIONS,\n",
        "      solutions.drawing_styles.get_default_pose_landmarks_style())\n",
        "  return annotated_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(640, 960, 3)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "img_path = \"./mediapipe-models/image.jpg\"\n",
        "\n",
        "img = cv2.imread(img_path)\n",
        "\n",
        "print(img.shape)\n",
        "\n",
        "# cv2.imshow('a', img)\n",
        "# cv2.waitKey(0)\n",
        "\n",
        "# # closing all open windows\n",
        "# cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzXuqyIBlXer"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "img_path = \"./mediapipe-models/images/cam0_0.png\"\n",
        "\n",
        "img = cv2.imread(img_path)\n",
        "\n",
        "scale_percent = 25  # percent of original size\n",
        "width = int(img.shape[1] * scale_percent / 100)\n",
        "height = int(img.shape[0] * scale_percent / 100)\n",
        "dim = (width, height)\n",
        "\n",
        "resized = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "cv2.imshow(\"a\", resized)\n",
        "cv2.waitKey(0)\n",
        "\n",
        "# closing all open windows\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-skLwMBmMN_"
      },
      "source": [
        "Optionally, you can upload your own image. If you want to do so, uncomment and run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etBjSdwImQPw"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for filename in uploaded:\n",
        "#   content = uploaded[filename]\n",
        "#   with open(filename, 'wb') as f:\n",
        "#     f.write(content)\n",
        "\n",
        "# if len(uploaded.keys()):\n",
        "#   IMAGE_FILE = next(iter(uploaded))\n",
        "#   print('Uploaded file:', IMAGE_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy4r2_ePylIa"
      },
      "source": [
        "## Running inference and visualizing the results\n",
        "\n",
        "The final step is to run pose landmark detection on your selected image. This involves creating your PoseLandmarker object, loading your image, running detection, and finally, the optional step of displaying the image with visualizations.\n",
        "\n",
        "Check out the [MediaPipe documentation](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/python) to learn more about configuration options that this solution supports.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "\n",
        "# Initialize MediaPipe Pose components.\n",
        "mp_pose = mp.solutions.pose\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "pose = mp_pose.Pose()\n",
        "\n",
        "# Load the input image.\n",
        "img_path = \"./mediapipe-models/images/cam0_0.png\"\n",
        "image = cv2.imread(img_path)\n",
        "\n",
        "# Convert the image from BGR to RGB.\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Process the image and get the pose landmarks.\n",
        "results = pose.process(image_rgb)\n",
        "\n",
        "# Draw the pose landmarks on the image.\n",
        "if results.pose_landmarks:\n",
        "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "\n",
        "# Resize the image for visualization.\n",
        "scale_percent = 25\n",
        "width = int(image.shape[1] * scale_percent / 100)\n",
        "height = int(image.shape[0] * scale_percent / 100)\n",
        "resized = cv2.resize(image, (width, height))\n",
        "\n",
        "# Display the image.\n",
        "cv2.imshow(\"Pose Detection\", resized)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JVO3rvPD4RN"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Import the necessary modules.\n",
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "\n",
        "# STEP 2: Create an PoseLandmarker object.\n",
        "base_options = python.BaseOptions(\n",
        "    model_asset_path=\"./mediapipe-models/pose_landmarker_lite.task\"\n",
        ")\n",
        "options = vision.PoseLandmarkerOptions(\n",
        "    base_options=base_options, output_segmentation_masks=True\n",
        ")\n",
        "detector = vision.PoseLandmarker.create_from_options(options)\n",
        "\n",
        "# STEP 3: Load the input image.\n",
        "image = mp.Image.create_from_file(img_path)\n",
        "\n",
        "# STEP 4: Detect pose landmarks from the input image.\n",
        "detection_result = detector.detect(image)\n",
        "\n",
        "# STEP 5: Process the detection result. In this case, visualize it.\n",
        "img = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
        "\n",
        "scale_percent = 25  # percent of original size\n",
        "width = int(img.shape[1] * scale_percent / 100)\n",
        "height = int(img.shape[0] * scale_percent / 100)\n",
        "dim = (width, height)\n",
        "\n",
        "resized = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "cv2.imshow(\"\", resized)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BwzFvaxwtPX"
      },
      "source": [
        "Visualize the pose segmentation mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jAIFzw9M3JJ"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\GGPC\\OneDrive\\Desktop\\P4P\\[MediaPipe_Python_Tasks]_Pose_Landmarker.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/GGPC/OneDrive/Desktop/P4P/%5BMediaPipe_Python_Tasks%5D_Pose_Landmarker.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m segmentation_mask \u001b[39m=\u001b[39m detection_result\u001b[39m.\u001b[39;49msegmentation_masks[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39mnumpy_view()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/GGPC/OneDrive/Desktop/P4P/%5BMediaPipe_Python_Tasks%5D_Pose_Landmarker.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m visualized_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrepeat(segmentation_mask[:, :, np\u001b[39m.\u001b[39mnewaxis], \u001b[39m3\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m255\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/GGPC/OneDrive/Desktop/P4P/%5BMediaPipe_Python_Tasks%5D_Pose_Landmarker.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,visualized_mask)\n",
            "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "segmentation_mask = detection_result.segmentation_masks[0].numpy_view()\n",
        "visualized_mask = np.repeat(segmentation_mask[:, :, np.newaxis], 3, axis=2) * 255\n",
        "cv2.imshow('',visualized_mask)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dslab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
